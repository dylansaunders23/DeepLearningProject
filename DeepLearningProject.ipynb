{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXLD5w3UyJrJInNGR3cTTx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylansaunders23/DeepLearningProject/blob/main/DeepLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Lyrics"
      ],
      "metadata": {
        "id": "oxmKGfJKy5NT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PART 1: Load Data**"
      ],
      "metadata": {
        "id": "VKheYK_4y6R8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data from Kaggle Datasource"
      ],
      "metadata": {
        "id": "8cHeqCX4nOso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz2AchaVzJ9D",
        "outputId": "2e4aa2ff-6983-47b8-d53a-91cbe99175b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npH_cURPzcQi",
        "outputId": "69f00058-0821-4a10-9e29-43b6e1966a3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "f01tYh7o16bg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "h7vQqZG24DZw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "hyEPFZqU4gVO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d juicobowley/drake-lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgDyG1TP49Os",
        "outputId": "1c25a254-dbdf-432f-b26a-9487dc6c4b19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading drake-lyrics.zip to /content\n",
            "\r  0% 0.00/764k [00:00<?, ?B/s]\n",
            "\r100% 764k/764k [00:00<00:00, 97.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d suraj520/music-dataset-song-information-and-lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DDbBHqiou7K",
        "outputId": "034029c0-1062-4858-ad7b-80d9b6f2fcbd"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading music-dataset-song-information-and-lyrics.zip to /content\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\n",
            "\r100% 1.90M/1.90M [00:00<00:00, 140MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip drake-lyrics.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bED2ZFPb5uDi",
        "outputId": "78925750-4017-4853-8d13-57c3993067d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drake-lyrics.zip\n",
            "  inflating: drake_data.csv          \n",
            "  inflating: drake_data.json         \n",
            "  inflating: drake_lyrics.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip music-dataset-song-information-and-lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Egi5DgIo1dW",
        "outputId": "1c541687-e8ec-4e6e-c842-b5de9ae0732d"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  music-dataset-song-information-and-lyrics.zip\n",
            "  inflating: songs.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QNhg885B5siH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other_dataset = pd.read_csv('/content/songs.csv')"
      ],
      "metadata": {
        "id": "tpS8IMQopSjJ"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drake_data.csv')"
      ],
      "metadata": {
        "id": "-MCX2sfH55yQ"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics = dataset.lyrics"
      ],
      "metadata": {
        "id": "xYplvULZ7C8i"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse the lyrics to get a list of words"
      ],
      "metadata": {
        "id": "2Se5n2WQnV3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "# NOTE:\n",
        "# need to download the 'punkt' and 'stopwords' depndencies from nltk, used by\n",
        "# tokenize and stopworks respectively:\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRPyTqBeAXeO",
        "outputId": "cd9ef36b-3bbf-468c-f79d-a737a1655724"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other artists"
      ],
      "metadata": {
        "id": "luro7HnEp9aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_lyrics_with_title_format(title, lyrics2):\n",
        "    # Extract the first line of lyrics\n",
        "    first_line = lyrics2.split('\\n')[0]\n",
        "\n",
        "    # Apply the regex pattern to the first line of lyrics\n",
        "    if re.search(fr'\\b{re.escape(title)}\\b', lyrics2, flags=re.IGNORECASE):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def remove_first_line(text):\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Join the lines, excluding the first one\n",
        "    new_text = '\\n'.join(lines[1:])\n",
        "\n",
        "    return new_text\n",
        "def filter_dataset_with_title_format(dataset):\n",
        "    # Initialize a list to store filtered rows\n",
        "    filtered_rows = []\n",
        "\n",
        "    # Iterate over each row of the dataset\n",
        "    for index, row in dataset.iterrows():\n",
        "        # Extract title and lyrics from the current row\n",
        "        title = row['Name']\n",
        "        lyrics2 = row['Lyrics']\n",
        "\n",
        "        # Check if the lyrics match the title format\n",
        "        if filter_lyrics_with_title_format(title, lyrics2):\n",
        "            # If match found, add the row to filtered rows\n",
        "            filtered_rows.append(row)\n",
        "\n",
        "    # Create a new DataFrame with the filtered rows\n",
        "    filtered_dataset = pd.DataFrame(filtered_rows)\n",
        "\n",
        "    return filtered_dataset"
      ],
      "metadata": {
        "id": "ifm2873spvdx"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drake Lyrics"
      ],
      "metadata": {
        "id": "4zXZcUfhqDGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  if isinstance(text, str):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove anything in brackets or parenthesis\n",
        "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.tokenize.word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "  else:\n",
        "    return ''"
      ],
      "metadata": {
        "id": "INpa1XPH7E4s"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics_only = filter_dataset_with_title_format(other_dataset)\n",
        "\n",
        "lyrics_only['Lyrics'] = lyrics_only['Lyrics'].apply(remove_first_line)\n",
        "\n",
        "lyrics_only.head()\n",
        "\n",
        "lyrics_only['Lyrics'] = lyrics_only['Lyrics'].apply(preprocess_text)\n",
        "\n",
        "lyrics2 = []\n",
        "for i in lyrics_only['Lyrics']:\n",
        "  lyrics2 += [i]\n",
        "\n",
        "print(lyrics2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1CG3NUxp7WP",
        "outputId": "be1e5f0d-acb0-46d4-f9af-7a2a6b91e21b"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sweet', 'lord', 'mmm', 'lord', 'mmm', 'lord', 'really', 'wan', 'na', 'see', 'really', 'wan', 'na', 'really', 'wan', 'na', 'see', 'lord', 'takes', 'long', 'lord', 'sweet', 'lord', 'mmm', 'lord', 'mmm', 'lord', 'really', 'wan', 'na', 'know', 'id', 'really', 'wan', 'na', 'go', 'really', 'wan', 'na', 'show', 'lord', 'wont', 'take', 'long', 'lord', 'sweet', 'lord', 'mmm', 'lord', 'sweet', 'lord', 'might', 'also', 'like', 'really', 'wan', 'na', 'see', 'really', 'wan', 'na', 'see', 'really', 'wan', 'na', 'see', 'lord', 'really', 'wan', 'na', 'see', 'lord', 'takes', 'long', 'lord', 'sweet', 'lord', 'mmm', 'lord', 'lord', 'really', 'wan', 'na', 'know', 'really', 'wan', 'na', 'go', 'really', 'wan', 'na', 'show', 'lord', 'wont', 'take', 'long', 'lord', 'mmmmm', 'sweet', 'lord', 'lord', 'mmm', 'lord', 'lord', 'oh', 'oh', 'sweet', 'lord', 'ooh', 'really', 'wan', 'na', 'see', 'really', 'wan', 'na', 'really', 'wan', 'na', 'see', 'lord', 'takes', 'long', 'lord', 'mmm', 'lord', 'lord', 'sweet', 'lord', 'sweet', 'lord', 'ah', 'oh', 'lord', 'mmmmm', 'mmmmm', 'mmmmm', 'mmmmm', 'sweet', 'lord', 'sweet', 'lord', 'lord', 'lord', 'sweet', 'lord', 'sweet', 'lord', 'sweet', 'lord', 'sweet', 'lord', '23embed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "processed_lyrics = preprocess_text(lyrics[0])\n",
        "processed_lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIoBLtyi8Lcb",
        "outputId": "7d793d57-49d8-4689-c9ab-bf663f4f5407"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['put',\n",
              " 'feelings',\n",
              " 'ice',\n",
              " 'always',\n",
              " 'gem',\n",
              " 'certified',\n",
              " 'lover',\n",
              " 'boy',\n",
              " 'somehow',\n",
              " 'still',\n",
              " 'heartless',\n",
              " 'heart',\n",
              " 'gettin',\n",
              " 'colder']"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first song's processed lyrics without stop words"
      ],
      "metadata": {
        "id": "fXpTm6s0nctJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create a list of all of the lyrics and tokenize them"
      ],
      "metadata": {
        "id": "wkZ1PAPPnkve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end_of_song_marker = ['ENDOFSONG']\n",
        "tokens = []\n",
        "for i in range(0, len(lyrics)):\n",
        "  if i != 213:\n",
        "    tokens += preprocess_text(lyrics[i])\n",
        "    tokens += end_of_song_marker\n",
        "\n",
        "tokens2 = []\n",
        "for i in range(0, len(lyrics2)):\n",
        "  tokens2 += lyrics2[i]\n",
        "  tokens2 += end_of_song_marker"
      ],
      "metadata": {
        "id": "WwQPJJuSAuGb"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Join the tokens back into a single string\n",
        "text = ' '.join(tokens)\n",
        "text2 = ' '.join(tokens2)\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer2 = Tokenizer()\n",
        "\n",
        "# Fit tokenizer on the text\n",
        "tokenizer.fit_on_texts([text])\n",
        "tokenizer2.fit_on_texts([text2])\n",
        "\n",
        "# Tokenize the list of tokens\n",
        "tokenized_sequence = tokenizer.texts_to_sequences([tokens])[0]\n",
        "tokenized_sequence2 = tokenizer2.texts_to_sequences([tokens2])[0]"
      ],
      "metadata": {
        "id": "HIaD45OUD4Gy"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokens), len(tokenized_sequence), len(tokens2), len(tokenized_sequence2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ekh3Xefhsz",
        "outputId": "91e065f6-3554-4885-d864-861ae3d58aac"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76128 76128 102142 102142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create sequences from each lyric to the next, stopped by the end of the song"
      ],
      "metadata": {
        "id": "81AJlk_qn0w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(tokens, tokenized_sequence):\n",
        "  sequences = []\n",
        "\n",
        "  for i in range (0, len(tokenized_sequence) - 1):\n",
        "      curr  = tokens[i]\n",
        "      next = tokens[i+1]\n",
        "      # If neither token is the end-of-song marker, add it to the current sequence\n",
        "      if curr != 'ENDOFSONG' and next != 'ENDOFSONG':\n",
        "          sequences.append([tokenized_sequence[i], tokenized_sequence[i+1]])\n",
        "\n",
        "\n",
        "  # Convert sequences to numpy array\n",
        "  sequences = np.array(sequences)\n",
        "\n",
        "  # Split sequences into input (X) and output (Y)\n",
        "  X = sequences[:, :-1]\n",
        "  Y = sequences[:, -1]\n",
        "\n",
        "  # Split the dataset into training (80%), validation (10%), and test (10%) sets\n",
        "  X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2)\n",
        "  X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5)\n",
        "\n",
        "  return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ],
      "metadata": {
        "id": "TQfQSpksLY7Y"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_drake, X_val_drake, X_test_drake, Y_train_drake, Y_val_drake, Y_test_drake = split_data(tokens, tokenized_sequence)"
      ],
      "metadata": {
        "id": "a63XLZ-Si2yd"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_other, X_val_other, X_test_other, Y_train_other, Y_val_other, Y_test_other = split_data(tokens2, tokenized_sequence2)"
      ],
      "metadata": {
        "id": "kbsHbR_CjBqp"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train_other), len(X_val_other), len(X_test_other))\n",
        "print(len(Y_train_other), len(Y_val_other), len(Y_test_other))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSmMXdqpxh9f",
        "outputId": "516cb866-b29d-40a5-b50d-97759caf831e"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80944 10118 10118\n",
            "80944 10118 10118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train_drake), len(X_val_drake), len(X_test_drake))\n",
        "print(len(Y_train_drake), len(Y_val_drake), len(Y_test_drake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab18hAelxphN",
        "outputId": "094be2e5-3191-485a-ec3a-197d8e422e91"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60441 7555 7556\n",
            "60441 7555 7556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOIvW3YCx9Qh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}